---
title: "Result4_Highdim"
output:
  workflowr::wflow_html:
    code_folding: hide
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Introduction

The experiment is based on the following simulation setting.

### Design setting

We sample the standard i.i.d. Gaussian measurement $X_{ij} \sim N(0,1)$ anda construct $X \in \mathbb{R}^p$ with $n = 500$ and $p = 50,500,5000,50000$.

### Signal setting

We sample the i.i.d. normal coefficients $\beta_j \sim N(0,\sigma_\beta^2)$ for $j \in J$ and $\beta_ j = 0$ otherwise, where $J$ is a set of randomly $s$ indices in $\{1,â‹¯,p\}$ chosen uniformly at random.

This signal will be called `pointnormal`.

We will fix $s = 20$ throughout this experiment.

### PVE

We fix PVE = 0.5.

### Packages / Libraries

A list of packages we have loaded is collapsed. Please click "code" to see the list.

```{r library, message = FALSE}
library(Matrix); library(ggplot2); library(cowplot); library(susieR); library(BGLR);
library(glmnet); library(varbvs2); library(ncvreg); library(L0Learn); library(varbvs);
standardize = FALSE
source('code/method_wrapper.R')
source('code/sim_wrapper.R')
```

## Results

The result is summarized below. 

```{r fig1, fig.height=10, fig.width=15}
res_df       = readRDS("results/highdim_pve0.5.RDS")
method_list  = c("Mr.ASH","VarBVS","BayesB","Blasso","SuSiE","E-NET","Lasso","SCAD","MCP","L0Learn")
method_level = c("Mr.ASH","E-NET","Lasso",
                 "SCAD","MCP","L0Learn",
                 "VarBVS","BayesB","Blasso","SuSiE")
col          = gg_color_hue(13)[1:11][-4]
#shape        = c(19,4,5,7,8,17,24,25,9,3,11)[-8]
shape        = c(19,17,24,25,9,3,11,4,5,7,8)[-4]
p_list       = c(50,500,5000,50000)
sdat         = data.frame()
for (i in 1:4) {
  sdat = rbind(sdat, data.frame(pred = colMeans(matrix(res_df[[i]]$pred, 20, 10)),
                                time = colMeans(matrix(res_df[[i]]$time, 20, 10)),
                                fit  = method_list,
                                p = p_list[i]))
}
sdat$fit = factor(sdat$fit, levels = method_level)

p1 = ggplot(sdat) + geom_line(aes(x = p, y = pred, color = fit)) +
  geom_point(aes(x = p, y = pred, color = fit, shape = fit), size = 2.5) +
  theme_cowplot(font_size = 14) +
  scale_x_continuous(trans = "log10", breaks = p_list) +
  labs(y = "predictior error (rmse / sigma)", x = "number of coefficients (p)") +
  theme(axis.line = element_blank(),
        plot.title = element_text(hjust = 0.5)) +
  scale_color_manual(values = col) +
  scale_shape_manual(values = shape) +
  scale_y_continuous(trans = "log10", breaks = c(1,1.1,1.2,1.3,1.4)) +
  coord_cartesian(ylim = c(1,sqrt(2)))

title     = ggdraw() + draw_label("Prediction Error (log-scale)", fontface = 'bold', size = 20) 
subtitle  = ggdraw() + draw_label("Scenario: IndepGauss + SparseNormal, n = 500, p = 50, 500, 5000, 50000, pve = 0.5", fontface  = 'bold', size = 18) 
p0        = ggplot() + geom_blank() + theme_cowplot() + theme(axis.line = element_blank())
fig_main  = plot_grid(p0,p1,p0, nrow = 1, rel_widths = c(0.3,0.6,0.3))
fig       = plot_grid(title,subtitle,fig_main, ncol = 1, rel_heights = c(0.06,0.06,0.95))
fig
```

```{r fig2, fig.height=10, fig.width=15}
res_df       = readRDS("results/highdim_pve0.5.RDS")
method_list  = c("Mr.ASH","VarBVS","BayesB","Blasso","SuSiE","E-NET","Lasso","SCAD","MCP","L0Learn")
method_level = c("Mr.ASH","E-NET","Lasso",
                 "SCAD","MCP","L0Learn",
                 "VarBVS","BayesB","Blasso","SuSiE")
p_list       = c(50,500,5000,50000)
sdat         = data.frame()
for (i in 1:4) {
  sdat = rbind(sdat, data.frame(pred = colMeans(matrix(res_df[[i]]$pred, 20, 10)),
                                time = colMeans(matrix(res_df[[i]]$time, 20, 10)),
                                fit  = method_list,
                                p = p_list[i]))
}
sdat$fit = factor(sdat$fit, levels = method_level)

p1 = ggplot(sdat) + geom_line(aes(x = p, y = time, color = fit)) +
  geom_point(aes(x = p, y = time, color = fit, shape = fit), size = 2.5) +
  theme_cowplot(font_size = 14) +
  scale_x_continuous(trans = "log10", breaks = p_list) +
  labs(y = "computation time (sec)", x = "number of coefficients (p)") +
  theme(axis.line = element_blank(),
        plot.title = element_text(hjust = 0.5)) +
  scale_color_manual(values = col) +
  scale_shape_manual(values = shape) +
  scale_y_continuous(trans = "log10")

title     = ggdraw() + draw_label("Computation time (log-scale)", fontface = 'bold', size = 20) 
subtitle  = ggdraw() + draw_label("Scenario: IndepGauss + SparseNormal, n = 500, p = 50, 500, 5000, 50000, pve = 0.5", fontface  = 'bold', size = 18) 
p0        = ggplot() + geom_blank() + theme_cowplot() + theme(axis.line = element_blank())
fig_main  = plot_grid(p0,p1,p0, nrow = 1, rel_widths = c(0.3,0.6,0.3))
fig       = plot_grid(title,subtitle,fig_main, ncol = 1, rel_heights = c(0.06,0.06,0.95))
fig
```

## Source code

The source code will be popped up when you click `code` on the right side. 

```{r code, eval = FALSE}
tdat1        = list()
n            = 500
p_range      = c(50,500,5000,50000)
s            = 20
method_list  = c("varbvs","bayesb","blasso","susie","enet","lasso","ridge","scad2","mcp2","l0learn")
method_list2 = c("mr.ash",method_list,"enet2","lasso2","ridge2","mr.ash.opt")
method_num   = length(method_list2)
iter_num     = 20
pred         = matrix(0, iter_num, method_num); colnames(pred) = method_list2
time         = matrix(0, iter_num, method_num); colnames(time) = method_list2


for (iter in 1:4) {
  p               = p_range[iter]
  for (i in 1:20) {
    data          = simulate_data(n, p, s = s, seed = i, signal = "normal", pve = 0.5)
    
    for (j in 1:length(method_list)) {
      fit.method    = get(paste("fit.",method_list[j],sep = ""))
      fit           = fit.method(data$X, data$y, data$X.test, data$y.test, seed = i)
      pred[i,j+1]   = fit$rsse / data$sigma / sqrt(n)
      time[i,j+1]   = fit$t
      
      if (method_list[j] == "lasso") {
        pred[i,method_num - 2] = fit$rsse2 / data$sigma / sqrt(n)
      } else if (method_list[j] == "enet") {
        pred[i,method_num - 3] = fit$rsse2 / data$sigma / sqrt(n)
      } else if (method_list[j] == "ridge") {
        pred[i,method_num - 1] = fit$rsse2 / data$sigma / sqrt(n)
      }
    }
    
    fit         = fit.mr.ash(data$X, data$y, data$X.test, data$y.test, seed = i,
                             sa2 = (2^((0:19) / 20) - 1)^2)
    pred[i,1]   = fit$rsse / data$sigma / sqrt(n)
    time[i,1]   = fit$t
    
    fit           = fit.mr.ash2(data$X, data$y, data$X.test, data$y.test, seed = i,
                                sa2 = c(0, 1 / s), sigma2 = data$sigma^2,
                                update.pi = FALSE, pi = c(1 - s/p, s/p),
                                beta.init = NULL, update.order = NULL)
    pred[i,method_num]  = fit$rsse / data$sigma / sqrt(n)
    time[i,method_num]  = fit$t
    
    print(c(pred[i,]))
  }
  tdat1[[iter]] = data.frame(pred = c(pred), time = c(time), fit = rep(method_list2, each = 20))
}
```

## System Configuration

Click the below Session Info.