---
title: "Result3_SignalShape"
output:
  workflowr::wflow_html:
    code_folding: hide
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Introduction

### Signal setting

We will use the following 6 different signal settings with the same sparsity $s = 20$.

(1) SparseLaplace: $\beta_j \sim \textrm{Laplace}(1)$ for $j \in J$ and $\beta_j = 0$ otherwise, where $J$ is a set of randomly $s$ indices in $\{1,\cdots,p\}$, chosen uniformly at random.
(2) SparseT2: $\beta_j \sim \textrm{t}_2$ for $j \in J$ and $\beta_j = 0$ otherwise, where $J$ is a set of randomly $s$ indices in $\{1,\cdots,p\}$, chosen uniformly at random.
(3) SparseT5: $\beta_j \sim \textrm{t}_5$ for $j \in J$ and $\beta_j = 0$ otherwise, where $J$ is a set of randomly $s$ indices in $\{1,\cdots,p\}$, chosen uniformly at random.
(4) SparseNormal: $\beta_j \sim N(0,\sigma_\beta^2)$ for $j \in J$ and $\beta_j = 0$ otherwise, where $J$ is a set of randomly $s$ indices in $\{1,\cdots,p\}$, chosen uniformly at random.
(5) SparseUniform: $\beta_j \sim \textrm{Unif}(0,1)$ for $j \in J$ and $\beta_j = 0$ otherwise, where $J$ is a set of randomly $s$ indices in $\{1,\cdots,p\}$, chosen uniformly at random.
(6) SparseConstant: $\beta_j = 1$ for $j \in J$ and $\beta_j = 0$ otherwise, where $J$ is a set of randomly $s$ indices in $\{1,\cdots,p\}$, chosen uniformly at random.

The following is the tail behaviors of the above signal generating probability distributions.

```{r tail, message = FALSE}
library(ggplot2); library(cowplot)
x = seq(-100,100,0.01)
dat = rbind(data.frame(x = x, y = dexp(abs(x), 1, log = TRUE) / 2, signal = "SparseLaplace"),
            data.frame(x = x, y = dt(x, df = 2, log = TRUE), signal = "SparseT2"),
            data.frame(x = x, y = dt(x, df = 5, log = TRUE), signal = "SparseT5"),
            data.frame(x = x, y = dnorm(x, log = TRUE), signal = "SparseNormal"))
ggplot(dat) + geom_line(aes(x = x, y = y, color = signal)) + 
  coord_cartesian(ylim = c(-50,0)) + theme_cowplot(font_size = 14) +
  theme(axis.line    = element_blank()) +
  labs(x = "x", y = "logpdf(x)")
```

### PVE

### Packages / Libraries

A list of packages we have loaded is collapsed. Please click "code" to see the list.

```{r library, message = FALSE}
library(Matrix); library(ggplot2); library(cowplot); library(susieR); library(BGLR);
library(glmnet); library(mr.ash); library(ncvreg); library(L0Learn); library(varbvs);
standardize = FALSE
source('code/method_wrapper.R')
source('code/sim_wrapper.R')
```

## Results 

```{r fig1, fig.height=13, fig.width=15}
res_df       = readRDS("results/signalshape_pve0.99.RDS")
method_list  = c("Mr.ASH","VarBVS","BayesB","Blasso","SuSiE","E-NET","Lasso","Ridge","SCAD","MCP","L0Learn")
method_level = c("Mr.ASH","E-NET","Lasso","Ridge",
                 "SCAD","MCP","L0Learn",
                 "VarBVS","BayesB","Blasso","SuSiE")
col          = gg_color_hue(13)[1:11]
for (i in 1:6) {
res_df[[i]]$fit   = rep(method_list, each = 20)
res_df[[i]]$fit   = factor(res_df[[i]]$fit, levels =  c("Mr.ASH","E-NET","Lasso","Ridge",
                                            "SCAD","MCP","L0Learn",
                                            "VarBVS","BayesB","Blasso","SuSiE"))
some              = c(1,2,3,5,6,7)
res_df[[i]] = res_df[[i]][res_df[[i]]$fit %in% method_level[some],]
}
pp = list()
signal_name = c("SparseLaplace","SparseT2","SparseT5","SparseNormal","SparseUnif","SparseConst")
for (i in 1:6) {
  d       = res_df[[i]]
  pp[[i]] = my.box2(d, "fit", "pred", cols = col[some], shapes = 1:6) +
  theme(axis.line    = element_blank(),
        axis.text.x  = element_text(angle = 45,hjust = 1),
        legend.position = "none") +
  geom_hline(yintercept = median(d$pred[d$fit == "Mr.ASH"]), col = col[1],
             linetype = "dotted", size = 1.5) +
  scale_y_continuous(trans = "log10", breaks = c(1,1.2,1.4,1.6,1.8,2.0)) +
  coord_cartesian(ylim = c(0.95,1.8))
  subtitle  = ggdraw() + draw_label(paste(paste("Signal: ",signal_name[i], sep = ""),"", sep = ""),
                                    fontface  = 'bold', size = 18)
  pp[[i]]   = plot_grid(subtitle, pp[[i]], ncol = 1, rel_heights = c(0.06,0.95))
}
fig_main  = plot_grid(pp[[2]],pp[[3]],pp[[1]],pp[[4]],pp[[5]],pp[[6]], nrow = 2, rel_widths = c(0.3,0.3,0.3,0.3))
title     = ggdraw() + draw_label("Prediction Error (log-scale)", fontface = 'bold', size = 20) 
subtitle  = ggdraw() + draw_label("Scenario: LowdimIndepGauss, n = 500, p = 2000, s = 20, pve = 0.99", fontface = 'bold', size = 18)
fig       = plot_grid(title,subtitle,fig_main, ncol = 1, rel_heights = c(0.04,0.06,0.95))
fig
```

```{r fig2, fig.height=7, fig.width=15}
sdat = rbind(res_df[[1]], res_df[[2]], res_df[[3]], res_df[[4]], res_df[[5]], res_df[[6]])
p1       = my.box2(res_df[[1]], "fit", "time", cols = col[some]) +
  theme(axis.line    = element_blank(),
        axis.text.x  = element_text(angle = 45,hjust = 1),
        legend.position = "none") +
  scale_y_continuous(trans = "log10", breaks = c(0.5,1,2,5,10,20))
p0        = ggplot() + geom_blank() + theme_cowplot() + theme(axis.line = element_blank())
fig_main  = plot_grid(p0,p1,p0, nrow = 1, rel_widths = c(0.6,0.6,0.6))
title     = ggdraw() + draw_label("Computation time (log-scale)", fontface = 'bold', size = 20) 
subtitle  = ggdraw() + draw_label("Scenario: IndepGauss + SparseSignals, n = 500, p = 2000, s = 20, pve = 0.99", fontface  = 'bold', size = 18) 
fig       = plot_grid(title,subtitle,fig_main, ncol = 1, rel_heights = c(0.1,0.06,0.95))
fig
```

## Source code

The source code will be popped up when you click `code` on the right side. 

```{r code, eval = FALSE}
tdat1        = list()
n            = 500
p            = 2000
s            = 20
signal_list  = c("lap","t2","t5","normal","unif","const")
method_list  = c("enet","lasso","scad","mcp","l0learn")
method_num   = length(method_list) + 1
iter_num     = 20
pred         = matrix(0, iter_num, method_num); colnames(pred) = c("mr.ash", method_list)
time         = matrix(0, iter_num, method_num); colnames(time) = c("mr.ash", method_list)

for (iter in 1:6) {
for (i in 1:20) {
  data          = simulate_data(n, p, s = s, seed = i, signal = signal_list[iter], pve = 0.99)


 
  for (j in 1:length(method_list)) {
    fit.method    = get(paste("fit.",method_list[j],sep = ""))
    fit           = fit.method(data$X, data$y, data$X.test, data$y.test, seed = i)
    pred[i,j+1]   = fit$rsse / data$sigma / sqrt(n)
    time[i,j+1]   = fit$t
  }
 
  fit         = fit.mr.ash(data$X, data$y, data$X.test, data$y.test, seed = i,
                           sa2 = (2^((0:19) / 5) - 1)^2)
  pred[i,1]   = fit$rsse / data$sigma / sqrt(n)
  time[i,1]   = fit$t
}
}
tdat1[[iter]] = data.frame(pred = c(pred), time = c(time), fit = rep(c("mr.ash", method_list), each = 20))
```

```{r code2, eval = FALSE}
# cross validation is fairly accurate
data          = simulate_data(n, p, s = s, seed = 1, signal = signal_list[1], pve = 0.99)
fit1          = fit.scad(data$X, data$y, data$X.test, data$y.test, seed = i)
res1          = c(data$y.test) - predict(fit1$fit, X = data$X.test, lambda = fit1$fit$lambda)
pred1         = sqrt(colMeans(res1^2)) / data$sigma

fit2          = fit.mcp(data$X, data$y, data$X.test, data$y.test, seed = i)
res2          = c(data$y.test) - predict(fit2$fit, X = data$X.test, lambda = fit2$fit$lambda)
pred2         = sqrt(colMeans(res2^2)) / data$sigma

fit3          = fit.enet(data$X, data$y, data$X.test, data$y.test, seed = i)
res3          = c(data$y.test) - predict(fit3$fit, newx = data$X.test, s = fit3$fit$lambda)
pred3         = sqrt(colMeans(res3^2))/ data$sigma

# compare with mr.ash
fit0          = fit.mr.ash(data$X, data$y, data$X.test, data$y.test, seed = i,
                           sa2 = (2^((0:19) / 10) - 1)^2)
pred0         = fit0$rsse / data$sigma / sqrt(n)

## thus mr.ash is better than the best
print(c(mr.ash = pred0,
        scad.best = as.numeric(pred1[which.min(pred1)]),
        scad.cv = as.numeric(pred1[which.min(fit1$fit$cve)]),
        mcp.best = as.numeric(pred2[which.min(pred2)]),
        mcp.cv = as.numeric(pred2[which.min(fit2$fit$cve)]),
        enet.best = as.numeric(pred3[which.min(pred3)]),
        enet.cv = as.numeric(pred3[which.min(fit3$fit$cvm)])))
```

## System Configuration

Click the below Session Info.