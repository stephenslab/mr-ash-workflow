---
title: "Figures_for_the_paper"
output:
  workflowr::wflow_html:
    code_folding: hide
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Introduction

This .Rmd documentation is to reproduce figures in the paper/manuscript.

```{r, message = FALSE}
library(Matrix); library(ggplot2); library(cowplot); library(susieR); library(BGLR);
library(glmnet); library(mr.ash.alpha); library(ncvreg); library(L0Learn); library(varbvs);
standardize = FALSE
source('code/method_wrapper.R')
source('code/sim_wrapper.R')
```

## Popular shrinkage operators

(1) Soft thresholding

$$S_{{\rm soft}, \lambda}(b) = {\rm sign}(b) \max \{|b| - \lambda, 0\} = \left\{\begin{array}{ll}
0, & |b| \leq \lambda \\
b - \lambda, & b > \lambda \\
b + \lambda, & b < -\lambda
\end{array} \right.$$

(2) Hard thresholding

$$S_{{\rm hard}, \lambda}(b) = {\rm sign}(b) (\max \{|b|, \lambda\} - \lambda) = \left\{\begin{array}{ll}
0, & |b| \leq \lambda \\
b, & b > \lambda \\
b, & b < -\lambda
\end{array} \right.$$

(3) SCAD (Smoothly Clipped Absolute Deviation)

$$S_{{\rm scad}, \lambda, \gamma}(b) = \left\{\begin{array}{ll}
S_{{\rm soft}, \lambda}(b), & |b| \leq 2 \lambda \\
\frac{S_{{\rm soft}, \gamma\lambda/(\gamma - 1)}(b)}{1 - (1 / (\gamma - 1))}, & 2\lambda < |b| \leq \gamma \lambda \\
b, & \gamma \lambda < |b|
\end{array}\right.$$

(4) MCP (Minimax Concave Penalty)

$$S_{{\rm mcp}, \lambda, \gamma}(b) = \left\{\begin{array}{ll}
\frac{S_{{\rm soft}, \lambda}(b)}{1 - (1 / (\gamma - 1))}, & |b| \leq \gamma \lambda \\
b, & \gamma \lambda < |b|
\end{array}\right.$$

```{r}
scad = function(b, lambda = 1, gamma = 3) {
  b1 = pmax(abs(b) - lambda, 0) * sign(b) * (abs(b) <= 2 * lambda)
  b2 = ((gamma-1) * b - sign(b) * gamma * lambda) / (gamma-2) * (abs(b) <= gamma * lambda) * (abs(b) > 2 * lambda)
  b3 = b * (abs(b) > gamma * lambda)
  return (b1+b2+b3)
}

mcp = function(b, lambda = 1, gamma = 2) {
  b1 = pmax(abs(b) - lambda, 0) * sign(b) * (b <= gamma * lambda) * gamma / (gamma-1)
  b2 = b * (abs(b) > gamma * lambda)
  return (b1+b2)
}

softt = function(b, lambda = 1) {
  return (pmax(abs(b) - lambda, 0) * sign(b))
}

hardt = function(b, lambda = 1) {
  return (b * (abs(b) >= lambda))
}
```

## MR.ASH shrinkage operator may resemble the popular shrinkage operators

```{r fig1, fig.height=7, fig.width=15}
postmean = function(b, pi, sa2 = 0:100, sigma2 = 1){
  phi = outer(b^2, 1 / 2 / (1 + 1 / sa2) / sigma2);
  phi = exp(phi - apply(phi, 1, max))
  
  phi = t(pi * t(phi) / sqrt(1 + sa2));
  phi = phi / rowSums(phi);
  out = c(colSums(t(phi) / (1 + 1 / sa2))) * b
  return (out)
}

sa2 = 0:100; b = seq(0,10,0.001)

pi = exp(-sa2)
pi = pi / sum(pi)
b_softt = postmean(b, pi)

pi = double(101)
pi[1] = 0.8; pi[101] = 0.2
b_mcp = postmean(b, pi)

pi = double(101)
pi[1] = 0.6; pi[101] = 0.4
b_hardt = postmean(b, pi, sa2 = sa2^5)

pi = double(101)
pi[1] = 0.5; pi[2:51] = 0.2/50; pi[101] = 0.3
b_scad = postmean(b, pi, sa2 = sa2)
df = data.frame(b = c(b,b,b,b), sb = c(b_softt, b_hardt, b_scad, b_mcp),
                sb2 = c(softt(b, lambda = 1.43),
                        hardt(b, lambda = 5),
                        scad(b, lambda = 1, gamma = 4),
                        mcp(b, lambda = 2)),
                operator = rep(c("soft","hard","scad","mcp"), each = length(b)))
df$operator = factor(df$operator, levels = c("soft","hard","scad","mcp"))

p1 = ggplot(df) + geom_line(aes(x = b, y = sb, color = operator)) +
  theme_cowplot(font_size = 14) + theme(axis.line = element_blank()) +
  labs(y = "shrinakge of b (S(b))", title = "MR.ASH shrinkage operators")
p2 = ggplot(df) + geom_line(aes(x = b, y = sb2, color = operator)) +
  theme_cowplot(font_size = 14) + theme(axis.line = element_blank()) +
  labs(title = "123")  +
  labs(y = "shrinakge of b (S(b))", title = "Well-known shrinkage/thresholding operators")

fig = plot_grid(p1,p2, nrow = 1)
title = ggdraw() + draw_label("MR.ASH Shrinkage operator may resemble the well-known shrinkage operators", fontface = 'bold', size = 20) 
fig = plot_grid(title, fig, nrow = 2, rel_heights = c(0.06,0.95))
fig
```

```{r fig2, fig.height=7, fig.width=15}
R.hardt = function(b, lambda = 1) {
  out = b^2/2
  out[b > lambda] = lambda^2/2
  exp(-out)
}

R.softt = function(b, lambda = 1) {
  out = lambda^2/2 + (b - lambda) * lambda
  out[b <= lambda] = b[b <= lambda]^2/2
  exp(-out)
}

R.scad = function(b, lambda = 1, gamma = 3) {
  out = lambda^2/2 + (b - lambda) * lambda
  out[b <= lambda] = b[b <= lambda]^2/2
  out[b > 2 * lambda] = lambda^2 * 3/2 + (gamma - 2) * lambda^2/2 * 
    (1 - (gamma - b[b > 2 * lambda] / lambda)^2 / (gamma - 2)^2)
  out[b > gamma * lambda] = lambda^2 * 3/2 + (gamma - 2) * lambda^2/2
  exp(-out)
}

R.mcp = function(b, lambda = 1, gamma = 2) {
  out = lambda^2/2 + (gamma - 1) * lambda^2 / 2 * 
  (1 - (gamma - b / lambda)^2 / (gamma - 1)^2)
  out[b > gamma * lambda] = lambda^2 / 2 + (gamma - 1) * lambda^2 / 2 
  out[b <= lambda] = b[b <= lambda]^2/2
  exp(-out)
}

marginal_shape = function(b, lambda = 1, gamma = 2, operator = "ridge") {
  if (operator == "ridge") {
    return (exp(-lambda * b^2/2))
  } else if (operator == "soft") {
    out = b
    out[b >= 0] = R.softt(b[b >= 0], lambda = lambda)
    out[b < 0] = R.softt(-b[b < 0], lambda = lambda)
    return (out)
  } else if (operator == "hard") {
    out = b
    out[b >= 0] = R.hardt(b[b >= 0], lambda = lambda)
    out[b < 0] = R.hardt(-b[b < 0], lambda = lambda)
    return (out)
  } else if (operator == "scad") {
    out = b
    out[b >= 0] = R.scad(b[b >= 0], lambda = lambda, gamma = gamma)
    out[b < 0] = R.scad(-b[b < 0], lambda = lambda, gamma = gamma)
    return (out)
  } else if (operator == "mcp") {
    out = b
    out[b >= 0] = R.mcp(b[b >= 0], lambda = lambda, gamma = gamma)
    out[b < 0] = R.mcp(-b[b < 0], lambda = lambda, gamma = gamma)
    return (out)
  }
}

b = seq(-5,5,0.001)
df = data.frame(b = c(b,b,b,b,b), sb = c(marginal_shape(b, operator = "ridge"),
                                         marginal_shape(b, operator = "soft"),
                                         marginal_shape(b, operator = "hard"),
                                         marginal_shape(b, operator = "scad"),
                                         marginal_shape(b, operator = "mcp")),
                operator = rep(c("normal","soft","hard","scad","mcp"), each = length(b)))
df$operator = factor(df$operator, levels = c("normal","soft","hard","scad","mcp"))
ggplot(df) + geom_line(aes(x = b, y = sb, color = operator)) +
  theme_cowplot(font_size = 14) + theme(axis.line = element_blank())
```

```{r fig3, fig.height=7, fig.width=15}
res_df       = readRDS("results/ridge_pve0.5.RDS")
p_list       = c(50,100,200,500,1000,2000)
method_list  = c("Mr.ASH","VarBVS","BayesB","Blasso","SuSiE","E-NET","Lasso","Ridge","SCAD","MCP","L0Learn","Ridge.opt")
col          = gg_color_hue(13)[1:11]
sdat = data.frame()
for (i in 1:6) {
  sdat       = rbind(sdat, data.frame(pred = colMeans(matrix(res_df[[i]]$pred,20,12)),
                                      time = colMeans(matrix(res_df[[i]]$time,20,12)),
                                      p = p_list[i],
                                      fit = method_list))
}
shape       = c(19,17,24,25,9,3,11,4,5,7,8)
sdat$fit    = factor(sdat$fit, levels =  c("Mr.ASH","E-NET","Lasso","Ridge",
                                           "SCAD","MCP","L0Learn",
                                           "VarBVS","BayesB","Blasso","SuSiE",
                                           "Ridge.opt"))
sdat1       = sdat[sdat$fit %in% c("Mr.ASH","E-NET","Lasso","Ridge","SCAD","MCP","L0Learn","Ridge.opt"),]

p1 = ggplot(sdat1) + geom_line(aes(x = p, y = pred, color = fit)) +
  geom_point(aes(x = p, y = pred, color = fit, shape = fit), size = 2.5) +
  theme_cowplot(font_size = 14) +
  scale_x_continuous(trans = "log10", breaks = p_list) +
  labs(y = "predictior error (rmse / sigma)", x = "number of coefficients (p)") +
  theme(axis.line = element_blank(),
        plot.title = element_text(hjust = 0.5)) +
  scale_color_manual(values = c(col[1:7],"gray50")) +
  scale_shape_manual(values = c(shape[1:7],15)) +
  scale_y_continuous(trans = "log10", limits = c(1.04,1.46), breaks = c(1.1,1.2,1.3,1.4))
fig_main  = p1
title     = ggdraw() + draw_label("Prediction Error (log-scale)", fontface = 'bold', size = 20) 
subtitle  = ggdraw() + draw_label("Scenario: IndepGauss + Normal, n = 500, p = 50,100,200,500,1000,2000, pve = 0.5", fontface  = 'bold', size = 18) 
fig       = plot_grid(title,subtitle,fig_main, ncol = 1, rel_heights = c(0.06,0.06,0.95))
fig
```

```{r fig4, fig.height=11, fig.width=15}
res_df       = readRDS("results/signalshape_pve0.99.RDS")
method_list  = c("Mr.ASH","VarBVS","BayesB","Blasso","SuSiE","E-NET","Lasso","Ridge","SCAD","MCP","L0Learn")
method_level = c("Mr.ASH","E-NET","Lasso","Ridge",
                 "SCAD","MCP","L0Learn",
                 "VarBVS","BayesB","Blasso","SuSiE")
col          = gg_color_hue(13)[1:11]
for (i in 1:6) {
res_df[[i]]$fit   = rep(method_list, each = 20)
res_df[[i]]$fit   = factor(res_df[[i]]$fit, levels =  c("Mr.ASH","E-NET","Lasso","Ridge",
                                            "SCAD","MCP","L0Learn",
                                            "VarBVS","BayesB","Blasso","SuSiE"))
some              = c(1,2,3,5,6,7)
res_df[[i]] = res_df[[i]][res_df[[i]]$fit %in% method_level[some],]
}
pp = list()
signal_name = c("SparseLaplace","SparseT2","SparseT5","SparseNormal","SparseUnif","SparseConst")
for (i in 1:6) {
  d       = res_df[[i]]
  pp[[i]] = my.box2(d, "fit", "pred", cols = col[some], shapes = 1:6) +
  theme(axis.line    = element_blank(),
        axis.text.x  = element_text(angle = 45,hjust = 1),
        legend.position = "none") +
  geom_hline(yintercept = mean(d$pred[d$fit == "Mr.ASH"]), col = col[1],
             linetype = "dotted", size = 1.5) +
  scale_y_continuous(trans = "log10", breaks = c(1,1.2,1.4,1.6,1.8,2.0)) +
  coord_cartesian(ylim = c(0.95,1.8))
  subtitle  = ggdraw() + draw_label(paste(paste("Signal: ",signal_name[i], sep = ""),"", sep = ""),
                                    fontface  = 'bold', size = 18)
  pp[[i]]   = plot_grid(subtitle, pp[[i]], ncol = 1, rel_heights = c(0.06,0.95))
}
fig_main  = plot_grid(pp[[2]],pp[[3]],pp[[1]],pp[[4]],pp[[5]],pp[[6]], nrow = 2, rel_widths = c(0.3,0.3,0.3,0.3))
title     = ggdraw() + draw_label("Prediction Error (log-scale)", fontface = 'bold', size = 20) 
subtitle  = ggdraw() + draw_label("Scenario: LowdimIndepGauss, n = 500, p = 2000, s = 20, pve = 0.99", fontface = 'bold', size = 18)
fig       = plot_grid(title,subtitle,fig_main, ncol = 1, rel_heights = c(0.03,0.04,0.95))
fig
```

```{r fig5, fig.height=11, fig.width=15}
res_df       = readRDS("results/sparsesignal.RDS")
sdat         = data.frame()
s_list       = c(1,5,20,100,500,2000)
col          = gg_color_hue(13)[1:11]
shape        = c(19,17,24,25,9,3,11,4,5,7,8)
for (i in 1:6) {
  sdat = rbind(sdat, data.frame(pred = colMeans(matrix(res_df[[i]]$pred, 20, 11)),
                                time = colMeans(matrix(res_df[[i]]$time, 20, 11)),
                                fit  = method_list,
                                s    = s_list[i]))
}
sdat$fit = factor(sdat$fit, levels = method_level)

p1 = ggplot(sdat) + geom_line(aes(x = s, y = pred, color = fit)) +
  geom_point(aes(x = s, y = pred, color = fit, shape = fit), size = 2.5) +
  scale_x_continuous(breaks = s_list, trans = "log10") +
  theme_cowplot(font_size = 14) +
  labs(y = "predictior error (rmse / sigma)", x = "number of nonzero coefficients (s)") +
  theme(axis.line = element_blank(),
        plot.title = element_text(hjust = 0.5)) +
  scale_color_manual(values = col) +
  scale_shape_manual(values = shape) +
  scale_y_continuous(trans = "log10", breaks = c(1,1.1,1.2,1.3,1.4)) +
  coord_cartesian(ylim = c(1,1.45))
title     = ggdraw() + draw_label("Prediction Error (log-scale)", fontface = 'bold', size = 20) 
subtitle  = ggdraw() + draw_label("Scenario: IndepGauss + SparseNormal, n = 500, p = 2000, s = 1,5,20,100,500,2000, pve = 0.5", fontface  = 'bold', size = 18) 
p0        = ggplot() + geom_blank() + theme_cowplot() + theme(axis.line = element_blank())
fig_main  = plot_grid(p0,p1,p0, nrow = 1, rel_widths = c(0.3,0.8,0.3))
fig       = plot_grid(title,subtitle,fig_main, ncol = 1, rel_heights = c(0.06,0.06,0.95))
fig
```

```{r fig6, fig.height=11, fig.width=15}
res_df       = readRDS("results/diffpve.RDS")
method_list  = c("Mr.ASH","VarBVS","BayesB","Blasso","SuSiE","E-NET","Lasso","Ridge","SCAD","MCP","L0Learn")
method_level = c("Mr.ASH","E-NET","Lasso","Ridge",
                 "SCAD","MCP","L0Learn",
                 "VarBVS","BayesB","Blasso","SuSiE")
col          = gg_color_hue(13)[1:11]
shape        = c(19,17,24,25,9,3,11,4,5,7,8)
pve_list     = seq(0,0.9,0.1)
sdat         = data.frame()
for (i in 1:10) {
  sdat = rbind(sdat, data.frame(pred = colMeans(matrix(res_df[[i]]$pred, 20, 11)),
                                time = colMeans(matrix(res_df[[i]]$time, 20, 11)),
                                fit  = method_list,
                                pve  = pve_list[i]))
}
sdat$fit = factor(sdat$fit, levels = method_level)

p1 = ggplot(sdat) + geom_line(aes(x = pve, y = pred, color = fit)) +
  geom_point(aes(x = pve, y = pred, color = fit, shape = fit), size = 2.5) +
  scale_x_continuous(breaks = pve_list) +
  theme_cowplot(font_size = 14) +
  labs(y = "predictior error (rmse / sigma)", x = "number of coefficients (p)") +
  theme(axis.line = element_blank(),
        plot.title = element_text(hjust = 0.5)) +
  scale_color_manual(values = col) +
  scale_shape_manual(values = shape) +
  scale_y_continuous(trans = "log10", breaks = c(1,1.1,1.2,1.3,1.4)) +
  coord_cartesian(ylim = c(1,1.5))

title     = ggdraw() + draw_label("Prediction Error (log-scale)", fontface = 'bold', size = 20) 
subtitle  = ggdraw() + draw_label("Scenario: IndepGauss + SparseNormal, n = 500, p = 2000, pve = 0 - 0.9", fontface  = 'bold', size = 18) 
p0        = ggplot() + geom_blank() + theme_cowplot() + theme(axis.line = element_blank())
fig_main  = plot_grid(p0,p1,p0, nrow = 1, rel_widths = c(0.3,0.8,0.3))
fig       = plot_grid(title,subtitle,fig_main, ncol = 1, rel_heights = c(0.06,0.06,0.95))
fig
```

```{r fig7, fig.height=11, fig.width=15}
res_df       = readRDS("results/highdim_pve0.5.RDS")
method_list  = c("Mr.ASH","VarBVS","BayesB","Blasso","SuSiE","E-NET","Lasso","SCAD","MCP","L0Learn")
method_level = c("Mr.ASH","E-NET","Lasso",
                 "SCAD","MCP","L0Learn",
                 "VarBVS","BayesB","Blasso","SuSiE")
col          = gg_color_hue(13)[1:11][-4]
shape        = c(19,17,24,25,9,3,11,4,5,7,8)[-4]
p_list       = c(50,500,5000,50000)
sdat         = data.frame()
for (i in 1:4) {
  sdat = rbind(sdat, data.frame(pred = colMeans(matrix(res_df[[i]]$pred, 20, 10)),
                                time = colMeans(matrix(res_df[[i]]$time, 20, 10)),
                                fit  = method_list,
                                p = p_list[i]))
}
sdat$fit = factor(sdat$fit, levels = method_level)

p1 = ggplot(sdat) + geom_line(aes(x = p, y = pred, color = fit)) +
  geom_point(aes(x = p, y = pred, color = fit, shape = fit), size = 2.5) +
  theme_cowplot(font_size = 14) +
  scale_x_continuous(trans = "log10", breaks = p_list) +
  labs(y = "predictior error (rmse / sigma)", x = "number of coefficients (p)") +
  theme(axis.line = element_blank(),
        plot.title = element_text(hjust = 0.5)) +
  scale_color_manual(values = col) +
  scale_shape_manual(values = shape) +
  scale_y_continuous(trans = "log10", breaks = c(1,1.1,1.2,1.3,1.4)) +
  coord_cartesian(ylim = c(1,sqrt(2)))

title     = ggdraw() + draw_label("Prediction Error (log-scale)", fontface = 'bold', size = 20) 
subtitle  = ggdraw() + draw_label("Scenario: IndepGauss + SparseNormal, n = 500, p = 50, 500, 5000, 50000, pve = 0.5", fontface  = 'bold', size = 18) 
p0        = ggplot() + geom_blank() + theme_cowplot() + theme(axis.line = element_blank())
fig_main  = plot_grid(p0,p1,p0, nrow = 1, rel_widths = c(0.3,0.8,0.3))
fig       = plot_grid(title,subtitle,fig_main, ncol = 1, rel_heights = c(0.06,0.06,0.95))
fig
```