---
title: "Result8_RealGenotype"
output:
  workflowr::wflow_html:
    code_folding: hide
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Introduction

The experiment is based on the following simulation setting.

### Design setting

We use 20 real genotype matrices from GTEx consortium (https://gtexportal.org/home/).

$n = 287$ and $p = 5732, 7659, 6857, 4012, 6356, 8683, 4076, 7178, 4847, 5141, 6535, 7537, 7263, 7011, 7468, 5020, 8760, 5995, 6440, 5456$. The number of coefficients $p$ varies from 4,012 to 8,760. The average size of $p$ is 6,401.3.

Also, columns of $X$ are very highly correlated (even some are perfectly correlated).

### Signal setting

We sample the i.i.d. normal coefficients $\beta_j \sim N(0,\sigma_\beta^2)$ for $j \in J$ and $\beta_ j = 0$ otherwise, where $J$ is a set of randomly $s$ indices in $\{1,â‹¯,p\}$c hosen uniformly at random.

This signal will be called `sparsenormal`.

We fix $s = 20$ throughout this experiment.

### PVE

Then we sample $y = X\beta + \epsilon$, where $\epsilon \sim N(0,\sigma^2 I_n)$.

We fix PVE = 0.5, where PVE is the proportion of variance explained, defined by

$$
{\rm PVE} = \frac{\textrm{Var}(X\beta)}{\textrm{Var}(X\beta) + \sigma^2},
$$
where $\textrm{Var}(a)$ denotes the sample variance of $a$ calculated using R function `var`. To this end, we set $\sigma^2 = \textrm{Var}(X\beta)$.

### Performance Measure

The above two figures display the prediction error. The prediction error we define here is

$$
\textrm{Pred.Err}(\hat\beta;y_{\rm test}, X_{\rm test}) = \frac{\textrm{RMSE}}{\sigma} = \frac{\|y_{\rm test} - X_{\rm test} \hat\beta \|}{\sqrt{n}\sigma}
$$

where $y_{\rm test}$ and $X_{\rm test}$ are test data sample in the same way. If $\hat\beta$ is fairly accurate, then we expect that $\rm RMSE$ is similar to $\sigma$. Therefore in average $\textrm{Pred.Err} \geq 1$ and the smaller the better.

## Methods

In what follows, we briefly describe the comparison methods.

### L0Learn

`L0Learn` R package provides a fast coordinate descent algorithm for the best subset regression.

[Fast Best Subset Selection: Coordinate Descent and Local Combinatorial Optimization Algorithms](https://arxiv.org/abs/1803.01454)

### SCAD, MCP

`ncvreg` R package provides a fast coordinate descent algorithm for the non-convex penalized linear regression method with well-known penalty functions SCAD and MCP.

[Coordinate descent algorithms for nonconvex penalized regression, with applications to biological feature selection](http://myweb.uiowa.edu/pbreheny/pdf/Breheny2011.pdf)

### Packages / Libraries

A list of packages we have loaded is collapsed. Please click "code" to see the list.

```{r, message = FALSE, warning = FALSE}
library(Matrix); library(ggplot2); library(cowplot); library(susieR); library(BGLR);
library(glmnet); library(varbvs2); library(ncvreg); library(L0Learn); library(varbvs);
standardize = FALSE
filepath = "data"
filelist = paste("data/", list.files(filepath, pattern = "*.RDS"), sep = "")
source('code/method_wrapper.R')
source('code/sim_wrapper.R')
```

## Results

The result is summarized below. 

```{r fig1, fig.height=7, fig.width=15, warning = FALSE, message = FALSE}
res_df       = readRDS("results/realgenotype.RDS")
sdat         = res_df
method_list  = c("Mr.ASH","VarBVS","BayesB","Blasso","SuSiE","E-NET","Lasso","Ridge","SCAD","MCP","L0Learn",
                 "Mr.ASH.order", "Mr.ASH.init")
sdat$fit     = rep(method_list, each = 20)
sdat$fit     = factor(sdat$fit, levels =  c("Mr.ASH","Mr.ASH.order", "Mr.ASH.init",
                                            "E-NET","Lasso","Ridge",
                                            "SCAD","MCP","L0Learn",
                                            "VarBVS","BayesB","Blasso","SuSiE"))

col = c(gg_color_hue(11)[1], "grey1", "grey51",gg_color_hue(11)[2:11])
p1 = my.box(sdat, "fit", "pred") + 
  scale_color_manual(values = col) +
  scale_fill_manual(values = col) +
  theme(axis.line    = element_blank(),
        axis.text.x  = element_text(angle = 45,hjust = 1),
        legend.position = "none") +
  geom_hline(yintercept = median(sdat$pred[sdat$fit == "Mr.ASH"]), col = gg_color_hue(11)[1],
             linetype = "dotted", size = 1.5) +
  scale_y_continuous(trans = "log10", breaks = c(1,1.1,1.2,1.3,1.4,1.5))
p0        = ggplot() + geom_blank() + theme_cowplot() + theme(axis.line = element_blank())
fig_main  = plot_grid(p0,p1,p0, nrow = 1, rel_widths = c(0.3,0.6,0.3))
title     = ggdraw() + draw_label("Prediction Error (log-scale)", fontface = 'bold', size = 20) 
subtitle  = ggdraw() + draw_label("Scenario: RealGenotype + SparseNormal, n = 287, p = 4012-8760, pve = 0.5", fontface  = 'bold', size = 18) 
fig       = plot_grid(title,subtitle,fig_main, ncol = 1, rel_heights = c(0.1,0.06,0.95))
fig
```

```{r fig2, fig.height=7, fig.width=15}
p2 = my.box(sdat, "fit", "time", values = gg_color_hue(11)[c(1,3,7,10,6,9,11,2,4,5,8)]) +
  theme(axis.line    = element_blank(),
        axis.text.x  = element_text(angle = 45,hjust = 1),
        legend.position = "none") +
  scale_y_continuous(trans = "log10")
fig_main  = plot_grid(p0,p2,p0, nrow = 1, rel_widths = c(0.3,0.6,0.3))
title     = ggdraw() + draw_label("Computation Time (log-scale)", fontface = 'bold', size = 20) 
subtitle  = ggdraw() + draw_label("Scenario: RealGenotype + SparseNormal, n = 287, p = 4012-8760, pve = 0.5", fontface  = 'bold', size = 18) 
fig       = plot_grid(title,subtitle,fig_main, ncol = 1, rel_heights = c(0.1,0.06,0.95))
fig
```

## Source code

The source code will be popped up when you click `code` on the right side. 

```{r code, message = FALSE, warning = FALSE, eval= FALSE}
library(Matrix); library(ggplot2); library(cowplot); library(susieR); library(BGLR);
library(glmnet); library(mr.ash); library(ncvreg); library(L0Learn); library(varbvs);
standardize = FALSE
filepath = "data"
filelist = paste("data/", list.files(filepath, pattern = "*.RDS"), sep = "")
source('code/method_wrapper.R')
source('code/sim_wrapper.R')
tdat1        = list()
method_list  = c("varbvs","bayesb","blasso","susie","enet","lasso","ridge","scad2","mcp2","l0learn")
method_num   = length(method_list) + 3
iter_num     = 20
pred         = matrix(0, iter_num, method_num);
colnames(pred) = c("mr.ash", method_list,"mr.ash.order","mr.ash.init")
time         = matrix(0, iter_num, method_num);
colnames(time) = c("mr.ash", method_list,"mr.ash.order","mr.ash.init")
n            = 287

for (i in 1:20) {
  data          = simulate_data(s = 20, seed = i, signal = "normal",
                                design = "realgenotype", filepath = filelist[i], pve = 0.5)
  
  for (j in 1:length(method_list)) {
    fit.method    = get(paste("fit.",method_list[j],sep = ""))
    fit           = fit.method(data$X, data$y, data$X.test, data$y.test, seed = i)
    pred[i,j+1]   = fit$rsse / data$sigma / sqrt(n)
    time[i,j+1]   = fit$t
    
    if (method_list[j] == "lasso") {
      lasso.path.order = mr.ash:::path.order(fit$fit$glmnet.fit)
      lasso.beta       = as.vector(coef(fit$fit))[-1]
      lasso.time       = c(fit$t, fit$t2)
    }
  }
 
  fit         = fit.mr.ash(data$X, data$y, data$X.test, data$y.test, seed = i,
                           sa2 = (2^((0:19) / 5) - 1)^2)
  pred[i,1]   = fit$rsse / data$sigma / sqrt(n)
  time[i,1]   = fit$t

  fit         = fit.mr.ash2(data$X, data$y, data$X.test, data$y.test, seed = i,
                            update.order = lasso.path.order,
                            sa2 = (2^((0:19) / 5) - 1)^2)
  pred[i,j+2] = fit$rsse / data$sigma / sqrt(n)
  time[i,j+2] = fit$t + lasso.time[2]
  
  fit         = fit.mr.ash2(data$X, data$y, data$X.test, data$y.test, seed = i,
                            beta.init = lasso.beta,
                            sa2 = (2^((0:19) / 5) - 1)^2)
  pred[i,j+3] = fit$rsse / data$sigma / sqrt(n)
  time[i,j+3] = fit$t + lasso.time[1]
  
  print(c(pred[i,]))
}
tdat1 = data.frame(pred = c(pred), time = c(time),
                   fit = rep(c("mr.ash", method_list,"mr.ash.order","mr.ash.init"), each = 20))
```

## System Configuration

Click the below Session Info.